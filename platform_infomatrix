!pip install --upgrade ultralytics gradio opencv-python torch


import cv2
import gradio as gr
from ultralytics import YOLO
import torch
from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import numpy as np
import tempfile
import shutil
import subprocess
import os


yolo_model = YOLO("yolov8n-face-lindevs.pt")


model_name = "prithivMLmods/Deep-Fake-Detector-v2-Model"
processor = ViTImageProcessor.from_pretrained(model_name)
deepfake_model = ViTForImageClassification.from_pretrained(model_name).eval()

device = "cuda" if torch.cuda.is_available() else "cpu"
deepfake_model.to(device)


def predict_face_deepfake(face_img):
    pil_img = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))
    inputs = processor(images=pil_img, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = deepfake_model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)[0]

    fake_prob = probs[0].item()
    real_prob = probs[1].item()
    label = "Deepfake" if fake_prob > real_prob else "Real"
    confidence = fake_prob if label == "Deepfake" else real_prob
    return label, confidence


def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    out_path = "output.mp4"
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out_video = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

    suspicious_frames = []

    frame_idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break


        results = yolo_model.predict(frame, verbose=False)[0]
        boxes = results.boxes.xyxy.cpu().numpy()

        for box in boxes:
            x1, y1, x2, y2 = map(int, box)
            face = frame[y1:y2, x1:x2]
            label, prob = predict_face_deepfake(face)


            if label == "Deepfake" and prob > 0.8:
                suspicious_frames.append(frame_idx)

            color = (0,0,255) if label=="Deepfake" else (0,255,0)
            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)
            cv2.putText(frame, f"{label} {prob:.2f}", (x1, y1-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        out_video.write(frame)
        frame_idx += 1

    cap.release()
    out_video.release()
    return out_path, suspicious_frames

def convert_to_mp4(input_file):
    tmp_mp4 = tempfile.NamedTemporaryFile(suffix=".mp4", delete=False)
    tmp_mp4_path = tmp_mp4.name
    tmp_mp4.close()

    command = [
        "ffmpeg", "-y", "-i", input_file,
        "-c:v", "libx264", "-preset", "fast", "-crf", "23",
        "-c:a", "aac",
        tmp_mp4_path
    ]
    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return tmp_mp4_path

def gradio_interface(file):
    # file.name — путь к загруженному файлу
    # Конвертируем его в mp4 через ffmpeg
    mp4_path = convert_to_mp4(file.name)
    out_video, suspicious = process_video(mp4_path)
    return out_video, f"Suspicious frames (first 10): {suspicious[:10]}"

iface = gr.Interface(
    fn=gradio_interface,
    inputs=gr.File(file_types=[".mp4", ".avi", ".mov", ".mkv"]),
    outputs=[gr.Video(), gr.Textbox()],
    title="Deepfake Detection Platform",
    description="Upload any video, automatically converted to mp4 and processed"
)
iface.launch()

